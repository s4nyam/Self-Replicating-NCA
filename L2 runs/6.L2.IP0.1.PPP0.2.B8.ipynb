{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8b1458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::autopep8==2.0.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::black==24.2.0=py310hff52083_0\n",
      "  - conda-forge/noarch::bleach==6.1.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::plotly==5.19.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytest==8.0.1=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::qtpy==2.4.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::sip==6.7.12=py310hc6cd4ac_0\n",
      "  - conda-forge/noarch::tqdm==4.66.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask==3.0.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::importlib_metadata==7.0.1=hd8ed1ab_0\n",
      "  - conda-forge/noarch::nltk==3.8.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt5-sip==12.12.2=py310hc6cd4ac_5\n",
      "  - conda-forge/noarch::pytoolconfig==1.2.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qdarkstyle==3.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtawesome==1.3.0=pyh9208f05_0\n",
      "  - conda-forge/noarch::yapf==0.40.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask-core==2024.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask-cors==4.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_client==8.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pylint==2.17.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::rope==1.12.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::s3transfer==0.10.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::distributed==2024.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::ipykernel==6.29.2=pyhd33586a_0\n",
      "  - conda-forge/linux-64::keyring==24.3.0=py310hff52083_0\n",
      "  - conda-forge/noarch::python-lsp-server==1.7.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_console==6.6.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt==5.15.9=py310h04931ad_5\n",
      "  - conda-forge/noarch::python-lsp-black==2.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtconsole-base==5.4.4=pyha770c72_0\n",
      "  - conda-forge/noarch::spyder-kernels==2.4.4=unix_pyh707e725_0\n",
      "  - conda-forge/linux-64::astropy==6.0.0=py310h1f7b6fc_0\n",
      "  - conda-forge/noarch::bokeh==3.3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.8.3=py310h62c0568_0\n",
      "  - conda-forge/noarch::nbconvert-core==7.16.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqtwebengine==5.15.9=py310h704022c_5\n",
      "  - conda-forge/linux-64::pytables==3.9.2=py310h374b01c_1\n",
      "  - conda-forge/noarch::qtconsole==5.4.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::statsmodels==0.14.1=py310h1f7b6fc_0\n",
      "  - conda-forge/noarch::jupyter_server==2.12.5=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib==3.8.3=py310hff52083_0\n",
      "  - conda-forge/noarch::nbconvert-pandoc==7.16.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::scikit-image==0.22.0=py310hcc13569_2\n",
      "  - conda-forge/noarch::seaborn-base==0.13.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::shap==0.44.0=cpu_py310h7af0403_7\n",
      "  - conda-forge/noarch::jupyter-lsp==2.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.25.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert==7.16.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook-shim==0.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn==0.13.2=hd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab==4.1.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==7.1.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask==2024.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter==1.0.0=pyhd8ed1ab_10\n",
      "  - conda-forge/noarch::hdijupyterutils==0.21.0=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::autovizwidget==0.21.0=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::sparkmagic==0.21.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::numpydoc==1.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::spyder==5.4.5=py310hff52083_0\n",
      "  - conda-forge/noarch::sphinxcontrib-applehelp==1.0.8=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-devhelp==1.0.6=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-htmlhelp==2.0.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-qthelp==1.0.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinx==7.2.6=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-serializinghtml==1.1.10=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.7=pyhd8ed1ab_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - ffmpeg=6.1.1\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    botocore-1.34.76           |pyge310_1234567_0         6.6 MB  conda-forge\n",
      "    ffmpeg-6.1.1               | gpl_h8007c5b_104         9.3 MB  conda-forge\n",
      "    gnutls-3.7.9               |       hb077bed_0         1.9 MB  conda-forge\n",
      "    libass-0.17.1              |       h8fe9dca_1         124 KB  conda-forge\n",
      "    libdrm-2.4.120             |       hd590300_0         296 KB  conda-forge\n",
      "    libopenvino-2023.3.0       |       h2e90f83_1         5.7 MB  conda-forge\n",
      "    libopenvino-auto-batch-plugin-2023.3.0|       hd5fc58b_1         112 KB  conda-forge\n",
      "    libopenvino-auto-plugin-2023.3.0|       hd5fc58b_1         232 KB  conda-forge\n",
      "    libopenvino-hetero-plugin-2023.3.0|       h3ecfda7_1         177 KB  conda-forge\n",
      "    libopenvino-intel-cpu-plugin-2023.3.0|       h2e90f83_1         9.7 MB  conda-forge\n",
      "    libopenvino-intel-gpu-plugin-2023.3.0|       h2e90f83_1         7.8 MB  conda-forge\n",
      "    libopenvino-ir-frontend-2023.3.0|       h3ecfda7_1         194 KB  conda-forge\n",
      "    libopenvino-onnx-frontend-2023.3.0|       hfbc7f12_1         1.5 MB  conda-forge\n",
      "    libopenvino-paddle-frontend-2023.3.0|       hfbc7f12_1         644 KB  conda-forge\n",
      "    libopenvino-pytorch-frontend-2023.3.0|       h59595ed_1         937 KB  conda-forge\n",
      "    libopenvino-tensorflow-frontend-2023.3.0|       h0bff32c_1         1.1 MB  conda-forge\n",
      "    libopenvino-tensorflow-lite-frontend-2023.3.0|       h59595ed_1         448 KB  conda-forge\n",
      "    libpciaccess-0.18          |       hd590300_0          28 KB  conda-forge\n",
      "    libva-2.21.0               |       hd590300_0         185 KB  conda-forge\n",
      "    libvpx-1.13.1              |       h59595ed_0         982 KB  conda-forge\n",
      "    nettle-3.9.1               |       h7ab15ed_0         988 KB  conda-forge\n",
      "    ocl-icd-2.3.2              |       hd590300_1         133 KB  conda-forge\n",
      "    openh264-2.4.1             |       h59595ed_0         718 KB  conda-forge\n",
      "    p11-kit-0.24.1             |       hc5aa10d_0         4.5 MB  conda-forge\n",
      "    pugixml-1.14               |       h59595ed_0         112 KB  conda-forge\n",
      "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
      "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        58.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  botocore           conda-forge/noarch::botocore-1.34.76-pyge310_1234567_0 \n",
      "  cloudpickle        conda-forge/noarch::cloudpickle-3.0.0-pyhd8ed1ab_0 \n",
      "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 \n",
      "  docutils           conda-forge/linux-64::docutils-0.20.1-py310hff52083_3 \n",
      "  ffmpeg             conda-forge/linux-64::ffmpeg-6.1.1-gpl_h8007c5b_104 \n",
      "  gnutls             conda-forge/linux-64::gnutls-3.7.9-hb077bed_0 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-7.1.0-pyha770c72_0 \n",
      "  libass             conda-forge/linux-64::libass-0.17.1-h8fe9dca_1 \n",
      "  libdrm             conda-forge/linux-64::libdrm-2.4.120-hd590300_0 \n",
      "  libidn2            conda-forge/linux-64::libidn2-2.3.7-hd590300_0 \n",
      "  libopenvino        conda-forge/linux-64::libopenvino-2023.3.0-h2e90f83_1 \n",
      "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-batch-plugin-2023.3.0-hd5fc58b_1 \n",
      "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-plugin-2023.3.0-hd5fc58b_1 \n",
      "  libopenvino-heter~ conda-forge/linux-64::libopenvino-hetero-plugin-2023.3.0-h3ecfda7_1 \n",
      "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-cpu-plugin-2023.3.0-h2e90f83_1 \n",
      "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-gpu-plugin-2023.3.0-h2e90f83_1 \n",
      "  libopenvino-ir-fr~ conda-forge/linux-64::libopenvino-ir-frontend-2023.3.0-h3ecfda7_1 \n",
      "  libopenvino-onnx-~ conda-forge/linux-64::libopenvino-onnx-frontend-2023.3.0-hfbc7f12_1 \n",
      "  libopenvino-paddl~ conda-forge/linux-64::libopenvino-paddle-frontend-2023.3.0-hfbc7f12_1 \n",
      "  libopenvino-pytor~ conda-forge/linux-64::libopenvino-pytorch-frontend-2023.3.0-h59595ed_1 \n",
      "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-frontend-2023.3.0-h0bff32c_1 \n",
      "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-lite-frontend-2023.3.0-h59595ed_1 \n",
      "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hd590300_0 \n",
      "  libtasn1           conda-forge/linux-64::libtasn1-4.19.0-h166bdaf_0 \n",
      "  libunistring       conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 \n",
      "  libva              conda-forge/linux-64::libva-2.21.0-hd590300_0 \n",
      "  libvpx             conda-forge/linux-64::libvpx-1.13.1-h59595ed_0 \n",
      "  nettle             conda-forge/linux-64::nettle-3.9.1-h7ab15ed_0 \n",
      "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.2-hd590300_1 \n",
      "  openh264           conda-forge/linux-64::openh264-2.4.1-h59595ed_0 \n",
      "  p11-kit            conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 \n",
      "  packaging          conda-forge/noarch::packaging-24.0-pyhd8ed1ab_0 \n",
      "  pugixml            conda-forge/linux-64::pugixml-1.14-h59595ed_0 \n",
      "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
      "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  importlib_metadata                       7.0.1-hd8ed1ab_0 --> 7.1.0-hd8ed1ab_0 \n",
      "  openssl                                  3.2.1-hd590300_0 --> 3.2.1-hd590300_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libopenvino-intel-cp | 9.7 MB    |                                       |   0% \n",
      "pugixml-1.14         | 112 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "libopenvino-auto-plu | 232 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-pytorch- | 937 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openh264-2.4.1       | 718 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-paddle-f | 644 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-2023.3.0 | 5.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 1.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libvpx-1.13.1        | 982 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.76     | 6.6 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libass-0.17.1        | 124 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x265-3.5             | 3.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    |                                       |   0% [A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    | #####2                                |  14% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenvino-auto-plu | 232 KB    | ##5                                   |   7% \u001b[A\u001b[A\n",
      "pugixml-1.14         | 112 KB    | #####2                                |  14% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    | ###3                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    | 5                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ########4                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    | 3                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     | #####################3                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pugixml-1.14         | 112 KB    | ##################################### | 100% \u001b[A\n",
      "pugixml-1.14         | 112 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | #############3                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    | ############################5         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-paddle-f | 644 KB    | 9                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    | ##                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-2023.3.0 | 5.7 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ##################1                   |  49% \u001b[A\u001b[A\n",
      "\n",
      "libopenvino-auto-plu | 232 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 1.1 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-2023.3.0 | 5.7 MB    | ###########5                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ######7                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ######################6               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-2023.3.0 | 5.7 MB    | ####################9                 |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ############################7         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.76     | 6.6 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-2023.3.0 | 5.7 MB    | ###############################2      |  85% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | #################################7    |  91% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-pytorch- | 937 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ######8                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-pytorch- | 937 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.76     | 6.6 MB    | #########2                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libass-0.17.1        | 124 KB    | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ############################6         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x265-3.5             | 3.2 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | #############3                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.76     | 6.6 MB    | ##################2                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x265-3.5             | 3.2 MB    | ###########################9          |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.76     | 6.6 MB    | ###########################8          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openh264-2.4.1       | 718 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openh264-2.4.1       | 718 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.76     | 6.6 MB    | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | #######################4              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ##############################3       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-paddle-f | 644 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-paddle-f | 644 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libvpx-1.13.1        | 982 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libvpx-1.13.1        | 982 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 1.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libass-0.17.1        | 124 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libass-0.17.1        | 124 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-2023.3.0 | 5.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ##################################### | 100% [A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.76     | 6.6 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x265-3.5             | 3.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): / WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libtorch-2.1.2             |cpu_mkl_hcefb67d_101        45.1 MB  conda-forge\n",
      "    pytorch-2.1.2              |cpu_mkl_py310haa9fb50_101        25.3 MB  conda-forge\n",
      "    sleef-3.5.1                |       h9b69904_2         1.5 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        71.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libtorch           conda-forge/linux-64::libtorch-2.1.2-cpu_mkl_hcefb67d_101 \n",
      "  pytorch            conda-forge/linux-64::pytorch-2.1.2-cpu_mkl_py310haa9fb50_101 \n",
      "  sleef              conda-forge/linux-64::sleef-3.5.1-h9b69904_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pytorch-2.1.2        | 25.3 MB   |                                       |   0% \n",
      "sleef-3.5.1          | 1.5 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "libtorch-2.1.2       | 45.1 MB   |                                       |   0% \u001b[A\u001b[A\n",
      "sleef-3.5.1          | 1.5 MB    | 3                                     |   1% \u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | ####                                  |  11% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | #######2                              |  19% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | ###########7                          |  32% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | #################6                    |  48% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | #######################4              |  63% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | ############################2         |  76% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | #################################     |  89% \u001b[A\u001b[A\n",
      "\n",
      "libtorch-2.1.2       | 45.1 MB   | #######################3              |  63% \u001b[A\u001b[A\n",
      "\n",
      "libtorch-2.1.2       | 45.1 MB   | ###########################3          |  74% \u001b[A\u001b[A\n",
      "\n",
      "libtorch-2.1.2       | 45.1 MB   | ##############################5       |  83% \u001b[A\u001b[A\n",
      "\n",
      "libtorch-2.1.2       | 45.1 MB   | #################################7    |  91% \u001b[A\u001b[A\n",
      "sleef-3.5.1          | 1.5 MB    | ##################################### | 100% \u001b[A\n",
      "sleef-3.5.1          | 1.5 MB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "pytorch-2.1.2        | 25.3 MB   | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y ffmpeg=6.1.1\n",
    "!conda install -y matplotlib=3.8.3\n",
    "!conda install -y pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd94bb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print(*args, **kwargs):\n",
    "    # Uncomment the next line to enable printing\n",
    "    # built_in_print(*args, **kwargs)\n",
    "    pass\n",
    "import torch\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "if not os.path.exists('NCA'):\n",
    "    os.makedirs('NCA')\n",
    "\n",
    "if not os.path.exists('PD'):\n",
    "    os.makedirs('PD')\n",
    "\n",
    "if not os.path.exists('GD'):\n",
    "    os.makedirs('GD')\n",
    "\n",
    "import time\n",
    "output_stamp = int(time.time())\n",
    "if not os.path.exists('Outputs_'+str(output_stamp)):\n",
    "    os.makedirs('Outputs_'+str(output_stamp))\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10**6)\n",
    "\n",
    "precision = 1\n",
    "torch.set_printoptions(precision=precision)\n",
    "WIDTH, HEIGHT = 200,200\n",
    "grid_size = (WIDTH, HEIGHT)\n",
    "print(\"Width and Height used are {} and {}\".format(WIDTH, HEIGHT))\n",
    "INIT_PROBABILITY = 0.0002\n",
    "min_pixels = max(0, int(WIDTH * HEIGHT * INIT_PROBABILITY))\n",
    "NUM_LAYERS = 2 # rest hidden and one alpha\n",
    "ALPHA = 0.5 # To make other cells active (we dont go with other values below 0.6 to avoid dead cells and premature livelihood)\n",
    "INHERTIANCE_PROBABILITY  = 0.1 # probability that neighboring cells will inherit by perturbation.\n",
    "parameter_perturbation_probability = 0.2\n",
    "print(\"Numbers of layers used are {}\".format(NUM_LAYERS))\n",
    "print(\"1 for alpha layer and rest {} for hidden\".format(NUM_LAYERS-1))\n",
    "NUM_STEPS = 1000\n",
    "num_steps = NUM_STEPS\n",
    "at_which_step_random_death = 9999999999 # Set this to infinity or high value if you never want to enter catastrophic deletion (random death happens at this generation)\n",
    "probability_death = 0.004 # 40 pixels die every generation\n",
    "print(\"Numbers of Time Steps are {}\".format(NUM_STEPS))\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "activation = 'sigmoid' # ['sigmoid','tanh','noact']\n",
    "frequency_dicts = []\n",
    "FPS = 10 # Speed of display for animation of NCA and plots\n",
    "marker_size = 2 # for plots\n",
    "everystep_weights = [] # Stores weigths of the NNs from every time step.\n",
    "KMEANS_K = 5\n",
    "enable_annotations_on_nca = True\n",
    "\n",
    "\n",
    "budget_per_cell = 8\n",
    "fixed_value = 0\n",
    "budget_counter_grid = np.zeros((WIDTH, HEIGHT)) + fixed_value\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "import random\n",
    "import copy\n",
    "from collections import Counter\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "ca_grids_for_later_analysis = []\n",
    "\n",
    "# def custom_activation(x):\n",
    "#     result = 0.05 * (x + 2)\n",
    "#     result = max(0, min(0.1, result))\n",
    "#     return result\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    updated_value = np.tanh(x)\n",
    "    updated_value_tensor = torch.tensor(updated_value, dtype=torch.float32)\n",
    "    return updated_value_tensor\n",
    "if(activation == 'sigmoid'):\n",
    "  class SimpleNN(nn.Module):\n",
    "      def __init__(self):\n",
    "          super(SimpleNN, self).__init__()\n",
    "          self.fc1 = nn.Linear(9 * NUM_LAYERS, NUM_LAYERS)\n",
    "          self.sigmoid = nn.Sigmoid()\n",
    "          self.fc2 = nn.Linear(NUM_LAYERS, NUM_LAYERS)\n",
    "          # Initialize weights and biases to zero\n",
    "          nn.init.zeros_(self.fc1.weight)\n",
    "          nn.init.zeros_(self.fc2.weight)\n",
    "          nn.init.zeros_(self.fc1.bias)\n",
    "          nn.init.zeros_(self.fc2.bias)\n",
    "      def forward(self, x):\n",
    "          x = self.fc1(x)\n",
    "          x = self.sigmoid(x)\n",
    "          x = self.fc2(x)\n",
    "          return x\n",
    "\n",
    "elif(activation == 'tanh'):\n",
    "  class SimpleNN(nn.Module):\n",
    "      def __init__(self):\n",
    "          super(SimpleNN, self).__init__()\n",
    "          self.fc1 = nn.Linear(9 * NUM_LAYERS, NUM_LAYERS)\n",
    "          self.tanh = nn.Tanh()\n",
    "          self.fc2 = nn.Linear(NUM_LAYERS, NUM_LAYERS)\n",
    "          # Initialize weights and biases to zero\n",
    "          nn.init.zeros_(self.fc1.weight)\n",
    "          nn.init.zeros_(self.fc2.weight)\n",
    "          nn.init.zeros_(self.fc1.bias)\n",
    "          nn.init.zeros_(self.fc2.bias)\n",
    "      def forward(self, x):\n",
    "          x = self.fc1(x)\n",
    "          x = self.tanh(x)\n",
    "          x = self.fc2(x)\n",
    "          return x\n",
    "\n",
    "elif(activation == 'noact'):\n",
    "  class SimpleNN(nn.Module):\n",
    "      def __init__(self):\n",
    "          super(SimpleNN, self).__init__()\n",
    "          self.fc1 = nn.Linear(9 * NUM_LAYERS, NUM_LAYERS)\n",
    "          self.fc2 = nn.Linear(NUM_LAYERS, NUM_LAYERS)\n",
    "          # Initialize weights and biases to zero\n",
    "          nn.init.zeros_(self.fc1.weight)\n",
    "          nn.init.zeros_(self.fc2.weight)\n",
    "          nn.init.zeros_(self.fc1.bias)\n",
    "          nn.init.zeros_(self.fc2.bias)\n",
    "      def forward(self, x):\n",
    "          x = self.fc1(x)\n",
    "          x = self.fc2(x)\n",
    "          return x\n",
    "\n",
    "\n",
    "elif(activation == 'relu'):\n",
    "  class SimpleNN(nn.Module):\n",
    "      def __init__(self):\n",
    "          super(SimpleNN, self).__init__()\n",
    "          self.fc1 = nn.Linear(9 * NUM_LAYERS, NUM_LAYERS)\n",
    "          self.relu = nn.ReLU()\n",
    "          self.fc2 = nn.Linear(NUM_LAYERS, NUM_LAYERS)\n",
    "          # Initialize weights and biases to zero\n",
    "          nn.init.zeros_(self.fc1.weight)\n",
    "          nn.init.zeros_(self.fc2.weight)\n",
    "          nn.init.zeros_(self.fc1.bias)\n",
    "          nn.init.zeros_(self.fc2.bias)\n",
    "      def forward(self, x):\n",
    "          x = self.fc1(x)\n",
    "          x = self.relu(x)\n",
    "          x = self.fc2(x)\n",
    "          return x\n",
    "else:\n",
    "  class SimpleNN(nn.Module):\n",
    "      def __init__(self):\n",
    "          super(SimpleNN, self).__init__()\n",
    "          self.fc1 = nn.Linear(9 * NUM_LAYERS, NUM_LAYERS)\n",
    "          self.leaky_relu = nn.LeakyReLU()\n",
    "          self.fc2 = nn.Linear(NUM_LAYERS, NUM_LAYERS)\n",
    "          # Initialize weights and biases to zero\n",
    "          nn.init.zeros_(self.fc1.weight)\n",
    "          nn.init.zeros_(self.fc2.weight)\n",
    "          nn.init.zeros_(self.fc1.bias)\n",
    "          nn.init.zeros_(self.fc2.bias)\n",
    "      def forward(self, x):\n",
    "          x = self.fc1(x)\n",
    "          x = self.leaky_relu(x)\n",
    "          x = self.fc2(x)\n",
    "          return x\n",
    "\n",
    "\n",
    "ca_nn = SimpleNN().to(DEVICE)\n",
    "\n",
    "# Calculate the number of parameters stepwise\n",
    "\n",
    "input_size_fc1 = 9 * NUM_LAYERS\n",
    "output_size_fc1 = NUM_LAYERS\n",
    "weight_params_fc1 = input_size_fc1 * output_size_fc1\n",
    "bias_params_fc1 = output_size_fc1\n",
    "\n",
    "input_size_fc2 = NUM_LAYERS\n",
    "output_size_fc2 = NUM_LAYERS\n",
    "weight_params_fc2 = input_size_fc2 * output_size_fc2\n",
    "bias_params_fc2 = output_size_fc2\n",
    "\n",
    "weight_params = weight_params_fc1 + weight_params_fc2\n",
    "bias_params = bias_params_fc1 + bias_params_fc2\n",
    "total_params = weight_params + bias_params\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Model Summary\")\n",
    "# Print the equations and the total number of parameters\n",
    "print(f\"Input Size: {input_size_fc1}\")\n",
    "print(f\"FC Layer 1 Weight Parameters: {input_size_fc1} * {output_size_fc1} = {weight_params_fc1}\")\n",
    "print(f\"FC Layer 1 Bias Parameters: {output_size_fc1}\")\n",
    "print(f\"FC Layer 2 Weight Parameters: {input_size_fc2} * {output_size_fc2} = {weight_params_fc2}\")\n",
    "print(f\"FC Layer 2 Bias Parameters: {output_size_fc2}\")\n",
    "print(f\"Total Number of Parameters: {total_params}\")\n",
    "for name, layer in ca_nn.named_children():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        input_size = layer.in_features\n",
    "        output_size = layer.out_features\n",
    "        if name == \"fc1\":\n",
    "            print(f\"Layer 1: {name}, Input Size: {input_size}, Output Size: {output_size_fc1}\")\n",
    "        elif name == \"fc2\":\n",
    "            print(f\"Layer 2: {name}, Input Size: {input_size_fc2}, Output Size: {output_size_fc2}\")\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "ca_grid = torch.zeros((NUM_LAYERS, WIDTH, HEIGHT), device=DEVICE, dtype=torch.float32)\n",
    "print(\"cagrid before\")\n",
    "print(ca_grid)\n",
    "random_tensor = torch.ones((WIDTH, HEIGHT))\n",
    "sorted_values, indices = random_tensor.view(-1).sort()\n",
    "mask = torch.zeros_like(random_tensor)\n",
    "shuffled_indices = indices.tolist()  # Convert indices to a list\n",
    "random.shuffle(shuffled_indices)     # Shuffle the list\n",
    "random_positions = shuffled_indices[:min_pixels]\n",
    "mask.view(-1)[random_positions] = 1.0\n",
    "for layer in range(0,NUM_LAYERS):\n",
    "  if (layer==0):\n",
    "    ca_grid[layer] = mask * (ALPHA + (1 - ALPHA) * random_tensor)  # Initialize the alpha channel with values greater than ALPHA\n",
    "  else:\n",
    "    ca_grid[layer] = mask * (ALPHA + (1 - ALPHA) * random_tensor * random.random())  # Initialize the other channel with values greater than ALPHA\n",
    "# ca_grid[0] = mask * (random_tensor) # Initialising only alpha channel\n",
    "# ca_grid[1] = mask * (random_tensor * random.random()) # Initialising a little amount of channel 1 with the idea that if a pixel is having some intensity in alpha, it should have some values in other channels.\n",
    "print(\"cagrid after\")\n",
    "print(ca_grid)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Weight Parameters:\")\n",
    "\n",
    "print(\"Individual Weight Parameters:\")\n",
    "for name, param in ca_nn.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "        print(f\"Weights: {param}\")\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Bias Parameters for FC1:\")\n",
    "print(ca_nn.fc1.bias)\n",
    "print(\"Bias Parameters for FC2:\")\n",
    "print(ca_nn.fc2.bias)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Entering update loop >>>>>\")\n",
    "\n",
    "def initialize_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_normal_(module.weight)\n",
    "        nn.init.zeros_(module.bias)\n",
    "def initialize_weights_to_zero(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.zeros_(module.weight)\n",
    "        nn.init.zeros_(module.bias)\n",
    "\n",
    "# Create a list of neural networks, one for each pixel\n",
    "ca_nn_list = [SimpleNN().to(DEVICE) for _ in range(WIDTH * HEIGHT)]\n",
    "\n",
    "# Initialize the weights for neural networks associated with live pixels\n",
    "# budget_per_cell = 8\n",
    "# fixed_value = 0\n",
    "# budget_counter_grid = np.zeros((WIDTH, HEIGHT)) + fixed_value\n",
    "\n",
    "\n",
    "for i in range(WIDTH):\n",
    "    for j in range(HEIGHT):\n",
    "        if ca_grid[0, i, j] > ALPHA:\n",
    "            ca_nn_list[i * WIDTH + j].apply(initialize_weights)\n",
    "\n",
    "def update_ca(ca_grid, ca_nn_list,frame_number):\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Inside updateCA function\")\n",
    "    new_ca_grid = ca_grid.clone()\n",
    "    print(\"New CA grid initialised temporarily:\")\n",
    "    print(new_ca_grid)\n",
    "\n",
    "    def process_neighborhood(i, j, idx, ca_nn_list):\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"Inside process_neighborhood function\")\n",
    "        neighborhood = torch.zeros(9 * NUM_LAYERS, device=DEVICE)\n",
    "        print(\"Empty tensor for neighborhood initialised temporarily:\")\n",
    "        print(neighborhood)\n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                ni, nj = (i + dx) % WIDTH, (j + dy) % HEIGHT\n",
    "                for l in range(NUM_LAYERS):\n",
    "                    neighborhood[(dx + 1) * 3 + (dy + 1) + l * 9] = ca_grid[l, ni, nj]\n",
    "        neighborhood = torch.unsqueeze(neighborhood, 0)\n",
    "        print(\"Neighborhood is :\")\n",
    "        print(neighborhood)\n",
    "        output = None  # Initialize output to None\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "\n",
    "        print(\"Weight Parameters at this step (no perturbation has happened at this step):\")\n",
    "\n",
    "        print(\"Individual Weight Parameters:\")\n",
    "        for name, param in ca_nn_list[idx].named_parameters():\n",
    "            if 'weight' in name:\n",
    "                print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "                print(f\"Weights: {param}\")\n",
    "\n",
    "\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "        print(\"Bias Parameters at this step for FC1:\")\n",
    "        print(ca_nn_list[idx].fc1.bias)\n",
    "        print(\"Bias Parameters at this step for FC2:\")\n",
    "        print(ca_nn_list[idx].fc2.bias)\n",
    "\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "        if((neighborhood > ALPHA).any()):\n",
    "          output = ca_nn_list[idx](neighborhood)\n",
    "          print(\"Inside if condition for (neighborhood > ALPHA).any() \")\n",
    "          if(random.random() < INHERTIANCE_PROBABILITY):\n",
    "            print(\"Reaching towards inheritance and performing pertubation too - inside if condition - random.random() < INHERTIANCE_PROBABILITY.\")\n",
    "            high_alpha_pixels = [(dx, dy) for dx in [-1, 0, 1] for dy in [-1, 0, 1] if ca_grid[0, (i + dx) % WIDTH, (j + dy) % HEIGHT] > ALPHA] # Find neighboring pixels with alpha values greater than ALPHA\n",
    "            if high_alpha_pixels:\n",
    "                # check again for livelihood of the pixels (if this if condition passed, that means there is at least one element that is greater than alpha.)\n",
    "                current_alpha_value = ca_grid[0, i, j]\n",
    "                print(\"current_alpha_value: \",current_alpha_value.item())\n",
    "                print(\"current_alpha_value: \",current_alpha_value.item())\n",
    "                print(\"current_alpha_value: \",current_alpha_value.item())\n",
    "                print(\"current_alpha_value: \",current_alpha_value.item())\n",
    "                high_alpha_values = [ca_grid[0, (i + dx) % WIDTH, (j + dy) % HEIGHT] for dx, dy in high_alpha_pixels]\n",
    "                print(\">>>> Hello! I am pixel at position {}, {}. My alive neighbors are at the positions {} whose values in Alpha channel are {}.\".format(i, j, high_alpha_pixels, high_alpha_values))\n",
    "                selected_pixel = random.choice(high_alpha_pixels)  # Select any random live pixel in the neighborhood\n",
    "                print(\"I am selecting pixel {}\".format(selected_pixel))\n",
    "                ni, nj = (i + selected_pixel[0]) % WIDTH, (j + selected_pixel[1]) % HEIGHT\n",
    "\n",
    "                # Check if the selected neural network has any non-zero weights\n",
    "                selected_nn_idx = ni * WIDTH + nj\n",
    "                selected_nn = ca_nn_list[selected_nn_idx]\n",
    "                has_nonzero_weights_selected = any(torch.any(param != 0) for param in selected_nn.parameters())\n",
    "\n",
    "                current_nn_idx = idx\n",
    "                current_nn = ca_nn_list[current_nn_idx]\n",
    "                has_nonzero_weights_current = any(torch.any(param != 0) for param in current_nn.parameters())\n",
    "\n",
    "                if not has_nonzero_weights_current:\n",
    "                    # Copy the neural network from the selected neighboring pixel\n",
    "                    ca_nn_list[idx] = copy.deepcopy(selected_nn)\n",
    "                    print(\"AM I EVEN ENTERING HERE\")\n",
    "                    print(\"AM I EVEN ENTERING HERE\")\n",
    "                    print(\"AM I EVEN ENTERING HERE\")\n",
    "                    print(\"AM I EVEN ENTERING HERE\")\n",
    "                    # Perturb neural network weights\n",
    "                    for name, param in ca_nn_list[idx].named_parameters():\n",
    "                        if 'weight' in name:\n",
    "                            mask = torch.rand_like(param.data) < parameter_perturbation_probability\n",
    "                            with torch.no_grad():\n",
    "                                param.data += mask * torch.randn_like(param.data)\n",
    "                else:\n",
    "                    ca_nn_list[idx] = copy.deepcopy(selected_nn)\n",
    "        else:\n",
    "          ca_nn_list[idx].apply(initialize_weights_to_zero)\n",
    "        can_nn_updated_single = copy.deepcopy(ca_nn_list[idx])\n",
    "        print(\"Ouptut from NN is :\")\n",
    "        print(output)\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "\n",
    "        print(\"Weight Parameters at this step (if perturbation, then it has already finished at this step):\")\n",
    "\n",
    "        print(\"Individual Weight Parameters:\")\n",
    "        for name, param in ca_nn_list[idx].named_parameters():\n",
    "            if 'weight' in name:\n",
    "                print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "                print(f\"Weights: {param}\")\n",
    "\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "        print(\"Bias Parameters at this step for FC1:\")\n",
    "        print(ca_nn_list[idx].fc1.bias)\n",
    "        print(\"Bias Parameters at this step for FC2:\")\n",
    "        print(ca_nn_list[idx].fc2.bias)\n",
    "\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "\n",
    "        if output is not None:\n",
    "            # print(\"returning output from this function: this 1 should be same as this 2\", output.squeeze().tolist())\n",
    "            return output.squeeze().tolist(), can_nn_updated_single\n",
    "        else:\n",
    "            # Return a default value (all zeros) if output is None\n",
    "            return [0.0] * NUM_LAYERS, can_nn_updated_single\n",
    "\n",
    "    idx = 0  # Index for the neural networks\n",
    "    ca_nn_list_temp = []\n",
    "    for i in range(WIDTH):\n",
    "        for j in range(HEIGHT):\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            print(\">>Right now I am using pixel at WIDTH {}, HEIGHT {}\".format(i,j))\n",
    "            updated_values, can_nn_updated_single = process_neighborhood(i, j, idx, ca_nn_list)\n",
    "            print(\"returning output from process_neighborhood function which is same as the ouptut of NN in high precision: \", updated_values)\n",
    "            for layer in range(NUM_LAYERS):\n",
    "                new_ca_grid[layer, i, j] = updated_values[layer]\n",
    "            ca_nn_list_temp.append(can_nn_updated_single)\n",
    "            idx += 1\n",
    "\n",
    "    print(\"Final updated grid :\")\n",
    "    print(new_ca_grid)\n",
    "    print(\"Final updated grid (and the values are set to 0 or dead for the pixels are below ALPHA.):\")\n",
    "    new_ca_grid_temp = new_ca_grid.clone()\n",
    "    print(\"now replace all pixels with their corresponding sigmoid values.\")\n",
    "    # now replace all pixels with their corresponding sigmoid values.\n",
    "    for x in range(WIDTH):\n",
    "      for y in range(HEIGHT):\n",
    "        for layer in range(NUM_LAYERS):\n",
    "          updated_value = sigmoid(new_ca_grid_temp[layer, x, y].cpu().numpy())\n",
    "          new_ca_grid_temp[layer, x, y] = updated_value # setting a value between 0 and 1 for the alive pixels.\n",
    "    print(new_ca_grid_temp)\n",
    "    print(\"now we will check for the ALPHA values as threshold\")\n",
    "    # now we will check for the ALPHA values as threshold\n",
    "    for x in range(WIDTH):\n",
    "      for y in range(HEIGHT):\n",
    "          # Check if any value in channel 0 is less than ALPHA at the current position\n",
    "          if (new_ca_grid_temp[0, x, y] <= ALPHA):\n",
    "            # If any value is less than ALPHA, set values in all layers at the current position to 0\n",
    "            for layer in range(NUM_LAYERS):\n",
    "                new_ca_grid_temp[layer, x, y] = 0.0\n",
    "    \n",
    "    \n",
    "    # Random ALPHA Death\n",
    "    counter_death = 0\n",
    "    index_death_collected = []\n",
    "    if(frame_number % at_which_step_random_death == 0): # Either you hard code the death with generation explicitly or by the \"budget\"\n",
    "        for x in range(WIDTH):\n",
    "            for y in range(HEIGHT):\n",
    "                # Check if any value in channel 0 is less than ALPHA at the current position\n",
    "                counter_death = counter_death + 1\n",
    "                if (random.random() < probability_death):\n",
    "                    # If any value is less than ALPHA, set values in all layers at the current position to 0\n",
    "                    for layer in range(NUM_LAYERS):\n",
    "                        new_ca_grid_temp[layer, x, y] = 0.0\n",
    "                        index_death_collected.append(counter_death)\n",
    "    # Emptying the weights of those deaths\n",
    "    if(len(index_death_collected)>0):\n",
    "        for ii in range(len(ca_nn_list_temp)):\n",
    "            if ii in index_death_collected:\n",
    "                ca_nn_list_temp[ii].apply(initialize_weights_to_zero)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Budget Counter Grid\n",
    "    # Budget Counter Grid\n",
    "    # Budget Counter Grid\n",
    "    \n",
    "    print(\"Budget counter grid before updating budget_counter_grid :\")\n",
    "    print(budget_counter_grid)\n",
    "    for i in range(WIDTH):\n",
    "        for j in range(HEIGHT):\n",
    "            if round(new_ca_grid_temp[0, i, j].item(),precision) > ALPHA:\n",
    "                budget_counter_grid[i,j] = budget_counter_grid[i,j] + 1 # Budget consumed per generation\n",
    "            if round(new_ca_grid_temp[0, i, j].item(),precision) <= ALPHA:\n",
    "                budget_counter_grid[i,j] = 0 # Counter to 0 all rest cases\n",
    "    print(\"Budget counter grid after updating budget_counter_grid :\")\n",
    "    print(budget_counter_grid)\n",
    "    \n",
    "    # Death Routine from previosu code but with budget counter grid condition\n",
    "    counter_death_budget = 0\n",
    "    index_death_collected_budget = []\n",
    "    for x in range(WIDTH):\n",
    "        for y in range(HEIGHT):\n",
    "            counter_death_budget = counter_death_budget + 1\n",
    "            if (budget_counter_grid[x,y]>budget_per_cell): # check for budget limit\n",
    "                # If any value is less than ALPHA, set values in all layers at the current position to 0\n",
    "                budget_counter_grid[x,y] = 0 # <<<<<<<RESET COUNTER>>>>>>>>>>>>\n",
    "                for layer in range(NUM_LAYERS):\n",
    "                    new_ca_grid_temp[layer, x, y] = 0.0\n",
    "                    index_death_collected_budget.append(counter_death_budget)\n",
    "\n",
    "    if(len(index_death_collected_budget)>0):\n",
    "        for ii in range(len(ca_nn_list_temp)):\n",
    "            if ii in index_death_collected_budget:\n",
    "                ca_nn_list_temp[ii].apply(initialize_weights_to_zero)\n",
    "\n",
    "    print(new_ca_grid_temp)\n",
    "    return new_ca_grid_temp, ca_nn_list_temp\n",
    "\n",
    "if not os.path.exists('sim_frames_png'):\n",
    "    os.makedirs('sim_frames_png')\n",
    "if not os.path.exists('sim_frames_pdf'):\n",
    "    os.makedirs('sim_frames_pdf')\n",
    "\n",
    "\n",
    "\n",
    "metadata = dict(title='Neural CA Simulation', artist='AI', comment='Neural CA Simulation')\n",
    "writer = FFMpegWriter(fps=FPS, metadata=metadata)\n",
    "\n",
    "all_colormaps = plt.colormaps()\n",
    "# colormaps = all_colormaps\n",
    "colormaps = ['magma']\n",
    "fig, axes = plt.subplots(1, NUM_LAYERS, figsize=(5 * NUM_LAYERS, 5))\n",
    "# plt.close(fig)\n",
    "import time\n",
    "stamp = int(time.time())\n",
    "with writer.saving(fig, \"NCA_video_{}.mp4\".format(stamp), dpi=600):\n",
    "    for frame in range(NUM_STEPS+1):\n",
    "        fig, axes = plt.subplots(1, NUM_LAYERS, figsize=(5 * NUM_LAYERS, 5))\n",
    "        if(NUM_LAYERS==2):\n",
    "            cax = fig.add_axes([0.08, 0.94, 0.08, 0.02])  # Adjust the position and size as needed\n",
    "        elif(NUM_LAYERS==3):\n",
    "            cax = fig.add_axes([0.05, 0.955, 0.08, 0.02])  # Adjust the position and size as needed\n",
    "        else:\n",
    "            cax = fig.add_axes([0.02, 0.98, 0.18, 0.02])  # Adjust the position and size as needed\n",
    "\n",
    "        # plt.tight_layout() \n",
    "        # append NN weithts here\n",
    "\n",
    "        if(frame == 0):\n",
    "            weights_list = []\n",
    "            for network in ca_nn_list:\n",
    "                state_dict = network.state_dict()\n",
    "                flattened_params = []\n",
    "                for param in state_dict.values():\n",
    "                    flattened_params.extend(param.view(-1).tolist())\n",
    "                weights_list.append(flattened_params)\n",
    "            everystep_weights.append(weights_list)\n",
    "            ca_grid = ca_grid\n",
    "            grid_data = ca_grid[layer].cpu().numpy()\n",
    "            if(enable_annotations_on_nca):\n",
    "                cell_std = torch.std(ca_grid[0]) # Std applied on alpha channel only\n",
    "                std_deviation_list = []\n",
    "                for weights in weights_list:\n",
    "                    # Convert the nested list to a PyTorch tensor\n",
    "                    weights_tensor = torch.tensor(weights, device=DEVICE, dtype=torch.float32)\n",
    "                    # Calculate the standard deviation for each nested list\n",
    "                    std_deviation = torch.std(weights_tensor)\n",
    "                    # Append the result to the list\n",
    "                    std_deviation_list.append(std_deviation.item())\n",
    "                std_deviation_tensor = torch.tensor(std_deviation_list, device=DEVICE, dtype=torch.float32)\n",
    "                ann_std = torch.std(std_deviation_tensor)\n",
    "                pixel_count = torch.nonzero(ca_grid[0]).size(0)\n",
    "                num_all_zeros = sum(torch.all(torch.tensor(weights, device=DEVICE, dtype=torch.float32) == 0).item() for weights in weights_list)\n",
    "                ann_count = (WIDTH*HEIGHT) - num_all_zeros\n",
    "                plt.suptitle(f'Generation#{frame + 1}, AliveCells#{pixel_count}, AliveANNs#{ann_count}, Cell  {round(cell_std.item(),3)}, ANNs   {round(ann_std.item(),3)}')\n",
    "            else:\n",
    "                plt.suptitle(f'Generation {frame + 1}')            \n",
    "            min_value = 0\n",
    "            max_value = 1\n",
    "            norm = Normalize(vmin=min_value, vmax=max_value)\n",
    "            for layer in range(NUM_LAYERS):\n",
    "                ax = axes[layer]\n",
    "                ax.clear()\n",
    "                im = ax.imshow(ca_grid[layer].cpu().numpy(), cmap=colormaps[0],interpolation='none', norm=norm)\n",
    "                ax.set_title(f'Layer {layer + 1}')\n",
    "            # plt.title(f'Generation {frame + 1}')\n",
    "            colorbar = fig.colorbar(im, cax=cax, orientation='horizontal', shrink=0.7)\n",
    "            mid_value = (min_value + max_value) / 2\n",
    "            ticks = [min_value, (min_value + mid_value) / 2, mid_value, (mid_value + max_value) / 2, max_value]  # Include midpoints\n",
    "            colorbar.set_ticks(ticks)\n",
    "            if(NUM_LAYERS==2):\n",
    "                colorbar.ax.tick_params(axis='x', labelsize=5)\n",
    "            elif(NUM_LAYERS==3):\n",
    "                colorbar.ax.tick_params(axis='x', labelsize=6)\n",
    "            else:\n",
    "                colorbar.ax.tick_params(axis='x', labelsize=7)\n",
    "            plt.subplots_adjust(top=0.9)\n",
    "            plt.savefig(os.path.join('sim_frames_pdf', f'{frame:07d}.pdf'),format='pdf', dpi=600)\n",
    "            plt.savefig(os.path.join('sim_frames_png', f'{frame:07d}.png'),format='png', dpi=600)\n",
    "            writer.grab_frame()\n",
    "        else:\n",
    "            grid_data = ca_grid[layer].cpu().numpy()\n",
    "            min_value = 0\n",
    "            max_value = 1\n",
    "            norm = Normalize(vmin=min_value, vmax=max_value)\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            print(\">>>>>>>>Simulation # {}\".format(frame))\n",
    "            ca_grid, ca_nn_list_updated_main = update_ca(ca_grid, ca_nn_list, frame)\n",
    "            ca_grids_for_later_analysis.append(ca_grid[0].cpu().numpy())\n",
    "            precision_multiplier = 10 ** precision\n",
    "            rounded_grid = (ca_grid[0] * precision_multiplier).round() / precision_multiplier # picking only ALPHA values for plot!!!!!!\n",
    "            unique_values, value_counts = torch.unique(rounded_grid, return_counts=True)\n",
    "            frequency_dict = {value.item(): count.item() for value, count in zip(unique_values, value_counts)}\n",
    "            frequency_dicts.append(frequency_dict)\n",
    "            weights_list = []\n",
    "            for network in ca_nn_list_updated_main:\n",
    "                state_dict = network.state_dict()\n",
    "                flattened_params = []\n",
    "                for param in state_dict.values():\n",
    "                    flattened_params.extend(param.view(-1).tolist())\n",
    "                weights_list.append(flattened_params)\n",
    "            everystep_weights.append(weights_list)\n",
    "            if(enable_annotations_on_nca):\n",
    "                cell_std = torch.std(ca_grid[0]) # Std applied on alpha channel only\n",
    "                std_deviation_list = []\n",
    "                for weights in weights_list:\n",
    "                    # Convert the nested list to a PyTorch tensor\n",
    "                    weights_tensor = torch.tensor(weights, device=DEVICE, dtype=torch.float32)\n",
    "                    # Calculate the standard deviation for each nested list\n",
    "                    std_deviation = torch.std(weights_tensor)\n",
    "                    # Append the result to the list\n",
    "                    std_deviation_list.append(std_deviation.item())\n",
    "                std_deviation_tensor = torch.tensor(std_deviation_list, device=DEVICE, dtype=torch.float32)\n",
    "                ann_std = torch.std(std_deviation_tensor)\n",
    "                pixel_count = torch.nonzero(ca_grid[0]).size(0)\n",
    "                num_all_zeros = sum(torch.all(torch.tensor(weights, device=DEVICE, dtype=torch.float32) == 0).item() for weights in weights_list)\n",
    "                ann_count = (WIDTH*HEIGHT) - num_all_zeros\n",
    "                plt.suptitle(f'Generation#{frame + 1}, AliveCells#{pixel_count}, AliveANNs#{ann_count}, Cell  {round(cell_std.item(),3)}, ANNs   {round(ann_std.item(),3)}')\n",
    "            else:\n",
    "                plt.suptitle(f'Generation {frame + 1}')    \n",
    "            for layer in range(NUM_LAYERS):\n",
    "                ax = axes[layer]\n",
    "                ax.clear()\n",
    "                im = ax.imshow(ca_grid[layer].cpu().numpy(), cmap=colormaps[0],interpolation='none', norm=norm)\n",
    "                ax.set_title(f'Layer {layer + 1}')\n",
    "            # plt.title(f'Generation {frame + 1}')\n",
    "            colorbar = fig.colorbar(im, cax=cax, orientation='horizontal', shrink=0.7)\n",
    "            mid_value = (min_value + max_value) / 2\n",
    "            ticks = [min_value, (min_value + mid_value) / 2, mid_value, (mid_value + max_value) / 2, max_value]  # Include midpoints\n",
    "            colorbar.set_ticks(ticks)\n",
    "            if(NUM_LAYERS==2):\n",
    "                colorbar.ax.tick_params(axis='x', labelsize=5)\n",
    "            elif(NUM_LAYERS==3):\n",
    "                colorbar.ax.tick_params(axis='x', labelsize=6)\n",
    "            else:\n",
    "                colorbar.ax.tick_params(axis='x', labelsize=7)\n",
    "            plt.subplots_adjust(top=0.9)\n",
    "            plt.savefig(os.path.join('sim_frames_pdf', f'{frame:07d}.pdf'),format='pdf', dpi=600)\n",
    "            plt.savefig(os.path.join('sim_frames_png', f'{frame:07d}.png'),format='png', dpi=600)\n",
    "            writer.grab_frame()\n",
    "            ca_nn_list = copy.deepcopy(ca_nn_list_updated_main)\n",
    "        # fig.close()\n",
    "        plt.close()\n",
    "        plt.close(fig)\n",
    "plt.close()\n",
    "print(\"Simulation completed.\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "nca_video_filename = \"NCA_video_{}.mp4\".format(stamp)\n",
    "command = f\"rm {nca_video_filename}\"\n",
    "subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "nca_video_filename = \"NCA_video_{}\".format(stamp)\n",
    "# Save video as well\n",
    "\n",
    "# Your Python variable for FPS and bitrate\n",
    "fps = FPS  # replace with your desired value\n",
    "bitrate = 10000  # replace with your desired value\n",
    "\n",
    "# Construct the bash command with both FPS and bitrate variables\n",
    "command = f\"ffmpeg -framerate {fps} -pattern_type glob -i 'sim_frames_png/*.png' -c:v libx264 -b:v {bitrate}k -pix_fmt yuv420p {nca_video_filename}.mp4\"\n",
    "\n",
    "# Run the command quietly (suppress output)\n",
    "subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# Display the combined NCA Simulation\n",
    "frames_folder = 'sim_frames_png'\n",
    "frame_files = [f for f in os.listdir(frames_folder) if f.endswith(\".png\")]\n",
    "frame_files.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "frames = []\n",
    "for frame_file in frame_files:\n",
    "    frame_path = os.path.join(frames_folder, frame_file)\n",
    "    frame = Image.open(frame_path)\n",
    "    frames.append(frame)\n",
    "\n",
    "# Define GIF-related parameters\n",
    "output_gif_path = \"NCA_gif_{}.gif\".format(str(stamp))\n",
    "desired_fps = FPS  # Add FPS definition\n",
    "duration = int(1000 / desired_fps)\n",
    "\n",
    "# Save frames as an animated GIF\n",
    "frames[0].save(\n",
    "    output_gif_path,\n",
    "    save_all=True,\n",
    "    append_images=frames[1:],\n",
    "    duration=duration,\n",
    "    loop=0,\n",
    "    disposal=2,\n",
    "    optimize=False\n",
    ")\n",
    "\n",
    "# Cleaning Current Directory\n",
    "source_path = \"NCA_gif_{}.gif\".format(str(stamp))\n",
    "destination_path = 'NCA'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"NCA_video_{}.mp4\".format(stamp)\n",
    "destination_path = 'NCA'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"sim_frames_png\"\n",
    "destination_path = 'NCA'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"sim_frames_pdf\"\n",
    "destination_path = 'NCA'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for step, frequency_dict in enumerate(frequency_dicts):\n",
    "    print(f\"Step {step + 1}:\")\n",
    "    for value, count in frequency_dict.items():\n",
    "        print(f\"  Value : {value}, Frequency : {count}\")\n",
    "\n",
    "for step, frequency_dict in enumerate(frequency_dicts):\n",
    "    print(f\"Step {step + 1}:\")\n",
    "    for value, count in list(frequency_dict.items()):\n",
    "        print(\"before round off\")\n",
    "        print(f\"  Value : {value}, Frequency : {count}\")\n",
    "\n",
    "        # Round off the 'value' to 1 decimal place and update the dictionary\n",
    "        rounded_value = round(value, 1)\n",
    "        frequency_dict[rounded_value] = frequency_dict.pop(value)\n",
    "\n",
    "        print(\"after round off\")\n",
    "        print(f\"  Value : {rounded_value}, Frequency : {count}\")\n",
    "for step, frequency_dict in enumerate(frequency_dicts):\n",
    "    print(f\"Step {step + 1}:\")\n",
    "    for value, count in frequency_dict.items():\n",
    "        print(f\"  Value : {value}, Frequency : {count}\")\n",
    "\n",
    "# Tool 1 PD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a larger figure size\n",
    "plt.figure(figsize=(10, 6))  # You can adjust the width and height as needed\n",
    "\n",
    "unique_keys = set()\n",
    "for frequency_dict in frequency_dicts:\n",
    "    unique_keys.update(frequency_dict.keys())\n",
    "\n",
    "# Sort the unique_keys in ascending order\n",
    "unique_keys = sorted(unique_keys)\n",
    "\n",
    "x_values = list(range(0, num_steps))\n",
    "y_values = {key: [] for key in unique_keys}\n",
    "for step, frequency_dict in enumerate(frequency_dicts):\n",
    "    for key in unique_keys:\n",
    "        if key in frequency_dict:\n",
    "            y_values[key].append(frequency_dict[key])\n",
    "        else:\n",
    "            y_values[key].append(0)\n",
    "\n",
    "for key in unique_keys:\n",
    "    plt.plot(x_values, y_values[key], label=f'Value {key:.{precision}f}')\n",
    "\n",
    "plt.xlabel('Step Number')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.savefig(\"tool1_PD.pdf\",format='pdf', dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "source_path = \"tool1_PD.pdf\"\n",
    "destination_path = 'PD'\n",
    "shutil.move(source_path, destination_path)\n",
    "# Tool 2 PD\n",
    "\n",
    "import math\n",
    "Global_Entropies_H_ts = []\n",
    "for step, frequency_dict in enumerate(frequency_dicts):\n",
    "  total_count_W = 0\n",
    "   = []\n",
    "  contributions = []\n",
    "   = 0\n",
    "  H_t = 0\n",
    "  total_states = 0\n",
    "  for value, count in frequency_dict.items():\n",
    "    if(value==0):\n",
    "      total_states = 1\n",
    "    else:\n",
    "      total_states = total_states + 1\n",
    "  for value, count in frequency_dict.items():\n",
    "    total_count_W = total_count_W + count\n",
    "  for value, count in frequency_dict.items():\n",
    "    .append(count/total_count_W)\n",
    "  for each_ in :\n",
    "    contributions.append((-each_) * math.log(each_))\n",
    "  for each in contributions:\n",
    "     =  + each\n",
    "  if(math.log(total_states) == 0):\n",
    "    H_t = \n",
    "  else:\n",
    "    H_t = (1/math.log(total_states)) * \n",
    "  Global_Entropies_H_ts.append(H_t)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "Global_Entropies_H_ts = Global_Entropies_H_ts\n",
    "steps = list(range(len(Global_Entropies_H_ts)))\n",
    "plt.plot(steps, Global_Entropies_H_ts, marker='o', markersize=marker_size, linestyle='-')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Entropy (H_t)')\n",
    "plt.title('Global Entropies over Steps')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tool2_PD.pdf\",format='pdf', dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "source_path = \"tool2_PD.pdf\"\n",
    "destination_path = 'PD'\n",
    "shutil.move(source_path, destination_path)\n",
    "# Tool 3 PD\n",
    "medians = []\n",
    "for step, frequency_dict in enumerate(frequency_dicts):\n",
    "    print(f\"Step {step + 1}:\")\n",
    "    values_with_repetitions = []\n",
    "    for value, count in frequency_dict.items():\n",
    "        values_with_repetitions.extend([value] * count)\n",
    "    values_with_repetitions.sort()\n",
    "    n = len(values_with_repetitions)\n",
    "    if n % 2 == 0:\n",
    "        median = (values_with_repetitions[n // 2 - 1] + values_with_repetitions[n // 2]) / 2\n",
    "    else:\n",
    "        median = values_with_repetitions[n // 2]\n",
    "    medians.append(median)\n",
    "    print(f\"  Median: {median:.{precision}f}\")\n",
    "\n",
    "\n",
    "def round_list_elements(input_list, precision):\n",
    "    rounded_list = [round(element, precision) for element in input_list]\n",
    "    return rounded_list\n",
    "medians = round_list_elements(medians, precision)\n",
    "\n",
    "total_count_W = 0\n",
    "for value, count in frequency_dict.items():\n",
    "  total_count_W = total_count_W + count # Which is also equal to width * height\n",
    "\n",
    "\n",
    "def kroncker_delta(x,y):\n",
    "  if(x==y):\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "import math\n",
    "ca_grids = ca_grids_for_later_analysis\n",
    "gross_cell_variance = []\n",
    "for y in range(len(ca_grids)): # total number_of_steps number of grids are there\n",
    "  _gross = 0\n",
    "  ca_grids_temp = ca_grids[y].flatten()\n",
    "  for z in range(len(ca_grids_temp)):\n",
    "    # print(round(ca_grids_temp[z],precision))\n",
    "     = kroncker_delta(round(ca_grids_temp[z],precision),medians[y])\n",
    "    _gross = _gross + (1-)\n",
    "  gross_cell_variance.append(1/math.sqrt(total_count_W) * math.sqrt(_gross))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "gross_cell_variance = gross_cell_variance\n",
    "steps = list(range(len(gross_cell_variance)))\n",
    "plt.plot(steps, gross_cell_variance, marker='o', markersize=marker_size, linestyle='-')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Variance (_gross)')\n",
    "plt.title(' gross over Steps')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tool3_PD.pdf\",format='pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "source_path = \"tool3_PD.pdf\"\n",
    "destination_path = 'PD'\n",
    "shutil.move(source_path, destination_path)\n",
    "# Tool 4 PD\n",
    "ca_grids = ca_grids_for_later_analysis\n",
    "for each_grid in ca_grids:\n",
    "  width = each_grid.shape[0]\n",
    "  height = each_grid.shape[1]\n",
    "  for i in range(width):\n",
    "    for j in range(height):\n",
    "      cell_value = each_grid[i][j]\n",
    "      # print(\"value before\",cell_value)\n",
    "      updated = round(cell_value,precision)\n",
    "      each_grid[i][j] = updated\n",
    "      # print(\"value after\",updated)\n",
    "\n",
    "print(ca_grids)\n",
    "\n",
    "def round_dict_keys(input_dict, precision):\n",
    "    rounded_dict = {}\n",
    "    for key, value in input_dict.items():\n",
    "        rounded_key = round(key, precision)\n",
    "        rounded_dict[rounded_key] = value\n",
    "    return rounded_dict\n",
    "\n",
    "normalized_frequency_dicts = []\n",
    "for step, frequency_dict in enumerate(frequency_dicts):\n",
    "    min_count = min(frequency_dict.values())\n",
    "    max_count = max(frequency_dict.values())\n",
    "    normalized_frequency_dict = {}\n",
    "    for value, count in frequency_dict.items():\n",
    "        if(min_count == max_count):\n",
    "          normalized_count = 0\n",
    "          normalized_frequency_dict[value] = normalized_count\n",
    "        else:\n",
    "          normalized_count = (count - min_count) / (max_count - min_count)\n",
    "          normalized_frequency_dict[value] = normalized_count\n",
    "    normalized_frequency_dicts.append(round_dict_keys(normalized_frequency_dict,precision))\n",
    "for step, normalized_frequency_dict in enumerate(normalized_frequency_dicts):\n",
    "    print(f\"Step {step + 1}:\")\n",
    "    for value, normalized_count in normalized_frequency_dict.items():\n",
    "        print(f\"  Value {value:}: Normalized Frequency {normalized_count}\")\n",
    "\n",
    "def get_neighbors_with_wrap_around(grid, row, col, window_size, grid_size):\n",
    "    neighbors = []\n",
    "    for i in range(-window_size, window_size + 1):\n",
    "        for j in range(-window_size, window_size + 1):\n",
    "            new_row, new_col = (row + i) % grid_size, (col + j) % grid_size\n",
    "            neighbors.append(grid[new_row][new_col])\n",
    "    return neighbors\n",
    "\n",
    "window_size = 1\n",
    "\n",
    "def frequency_of(key, my_dict):\n",
    "    # print(\"key as input\", key)\n",
    "    key = round(key,precision)\n",
    "    key = min(my_dict, key=lambda x: abs(x - key))\n",
    "    # print(\"key after precision\", key)\n",
    "    if key in my_dict:\n",
    "        return my_dict[key]\n",
    "    else:\n",
    "        return None\n",
    "import copy\n",
    "mu_loc_data = []\n",
    "for each_grid,frequency_dict_temp in zip(ca_grids,normalized_frequency_dicts):\n",
    "  # frequency_dict_temp = round_dict_keys(frequency_dict_temp,precision)\n",
    "  width = each_grid.shape[0]\n",
    "  height = each_grid.shape[1]\n",
    "  grid_size = each_grid.shape[0]\n",
    "  rows = width # Replace 'rows' with the number of rows you want\n",
    "  cols = height  # Replace 'cols' with the number of columns you want\n",
    "  mu_locs_list_2d = []\n",
    "  for i in range(rows):\n",
    "      mu_locs_list_2d.append([None] * cols)\n",
    "  for i in range(width):\n",
    "    for j in range(height):\n",
    "      current_cell = each_grid[i][j]\n",
    "      current_cell_index_row = i\n",
    "      current_cell_index_column = j\n",
    "      # print(each_grid)\n",
    "      neighbors_of_current_cell = get_neighbors_with_wrap_around(each_grid,current_cell_index_row,current_cell_index_column,window_size,grid_size)\n",
    "      # print(\"neighbors\",neighbors_of_current_cell)\n",
    "      sum_of_frequencies_of_cell = 0\n",
    "      for each_neighbor in neighbors_of_current_cell:\n",
    "        # print(\"pciked neighbor\",each_neighbor)\n",
    "        # print(\"frequency dict\",frequency_dict_temp)\n",
    "        sum_of_frequencies_of_cell = sum_of_frequencies_of_cell + frequency_of(each_neighbor,frequency_dict_temp)\n",
    "      mu_loc_current_cell = sum_of_frequencies_of_cell/9\n",
    "      mu_locs_list_2d[i][j] = mu_loc_current_cell\n",
    "  mu_loc_data.append(mu_locs_list_2d)\n",
    "\n",
    "\n",
    "\n",
    "def get_neighbors_with_wrap_around(grid, row, col, window_size, grid_size):\n",
    "    neighbors = []\n",
    "    for i in range(-window_size, window_size + 1):\n",
    "        for j in range(-window_size, window_size + 1):\n",
    "            new_row, new_col = (row + i) % grid_size, (col + j) % grid_size\n",
    "            neighbors.append(grid[new_row][new_col])\n",
    "    return neighbors\n",
    "\n",
    "window_size = 1\n",
    "\n",
    "def frequency_of(key, my_dict):\n",
    "    # print(\"key as input\", key)\n",
    "    key = round(key,precision)\n",
    "    key = min(my_dict, key=lambda x: abs(x - key))\n",
    "    # print(\"key after precision\", key)\n",
    "    if key in my_dict:\n",
    "        return my_dict[key]\n",
    "    else:\n",
    "        return None\n",
    "import copy\n",
    "import math\n",
    "sigma_loc_data = []\n",
    "for each_grid,frequency_dict_temp,mu_data in zip(ca_grids,normalized_frequency_dicts,mu_loc_data):\n",
    "  # frequency_dict_temp = round_dict_keys(frequency_dict_temp,precision)\n",
    "  width = each_grid.shape[0]\n",
    "  height = each_grid.shape[1]\n",
    "  grid_size = each_grid.shape[0]\n",
    "  rows = width\n",
    "  cols = height\n",
    "  sigma_locs_list_2d = []\n",
    "  for i in range(rows):\n",
    "      sigma_locs_list_2d.append([None] * cols)\n",
    "  for i in range(width):\n",
    "    for j in range(height):\n",
    "      current_cell = each_grid[i][j]\n",
    "      current_cell_index_row = i\n",
    "      current_cell_index_column = j\n",
    "      neighbors_of_current_cell = get_neighbors_with_wrap_around(each_grid,current_cell_index_row,current_cell_index_column,window_size,grid_size)\n",
    "      sum_of_squared_frequencies = 0\n",
    "      for each_neighbor in neighbors_of_current_cell:\n",
    "        difference = frequency_of(each_neighbor,frequency_dict_temp) - mu_data[i][j]\n",
    "        squared = difference ** 2\n",
    "        sum_of_squared_frequencies = sum_of_squared_frequencies + squared\n",
    "      sigma_loc_current_cell = math.sqrt(sum_of_squared_frequencies)/3\n",
    "      sigma_locs_list_2d[i][j] = sigma_loc_current_cell\n",
    "  sigma_loc_data.append(sigma_locs_list_2d)\n",
    "\n",
    "\n",
    "\n",
    "mu_global = []\n",
    "for a in range(len(ca_grids)):\n",
    "  mu_g = 0\n",
    "  W = ca_grids[a].shape[0] * ca_grids[a].shape[1]\n",
    "  for x in range(ca_grids[a].shape[0]):\n",
    "    for y in range(ca_grids[a].shape[1]):\n",
    "      mu_g = mu_g + sigma_loc_data[a][x][y]\n",
    "  mu_g = mu_g/W\n",
    "  mu_global.append(mu_g)\n",
    "\n",
    "# print(mu_global)\n",
    "\n",
    "sigma_global = []\n",
    "for a in range(len(ca_grids)):\n",
    "  mu_glob = mu_global[a]\n",
    "  sigma_sum = 0\n",
    "  W = ca_grids[a].shape[0] * ca_grids[a].shape[1]\n",
    "  for x in range(ca_grids[a].shape[0]):\n",
    "    for y in range(ca_grids[a].shape[1]):\n",
    "      sigma_sum = sigma_sum + (sigma_loc_data[a][x][y] - mu_glob)**2\n",
    "  sigma_root = math.sqrt(sigma_sum)\n",
    "  sigma_globa = sigma_root/math.sqrt(W)\n",
    "  sigma_global.append(sigma_globa)\n",
    "# print(sigma_global)\n",
    "  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sigma_global = sigma_global\n",
    "steps = list(range(len(sigma_global)))\n",
    "plt.plot(steps, sigma_global, marker='o', markersize=marker_size, linestyle='-')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Variance (_global)')\n",
    "plt.title(' global over Steps using Local Organzation of Cells')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tool4_PD.pdf\",format='pdf', dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "source_path = \"tool4_PD.pdf\"\n",
    "destination_path = 'PD'\n",
    "shutil.move(source_path, destination_path)\n",
    "# Plot tools PD 2,3,4\n",
    "import matplotlib.pyplot as plt\n",
    "plot_data_tool2 = Global_Entropies_H_ts\n",
    "plot_data_tool3 = gross_cell_variance\n",
    "plot_data_tool4 = sigma_global\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(plot_data_tool2, marker='o', markersize=marker_size, label='H$_t$') #  for Tool 2\n",
    "ax.plot(plot_data_tool3, marker='s', markersize=marker_size, label='$_{gross}$') # for Tool 3\n",
    "ax.plot(plot_data_tool4, marker='^', markersize=marker_size, label='$_{glob}$') # for Tool 4\n",
    "ax.set_xlabel('X-axis Label')\n",
    "ax.set_ylabel('Y-axis Label')\n",
    "ax.set_title('All Tool Information in a Single Plot')\n",
    "ax.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tool234_PD.pdf\",format='pdf', dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "source_path = \"tool234_PD.pdf\"\n",
    "destination_path = 'PD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "# GD Tools:\n",
    "# RWSP Tool Tool 1\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "number_of_random_weights = 3\n",
    "\n",
    "import math\n",
    "this_list_should_contain_NN_for_every_step = everystep_weights\n",
    "def round_elements_in_nested_list(input_list, precision=2):\n",
    "    if isinstance(input_list, list):\n",
    "        return [round_elements_in_nested_list(elem, precision) for elem in input_list]\n",
    "    else:\n",
    "        return round(input_list, precision)\n",
    "\n",
    "rounded_list = round_elements_in_nested_list(this_list_should_contain_NN_for_every_step, precision)\n",
    "rounded_list_further = rounded_list\n",
    "round_list_array = np.array(rounded_list_further)\n",
    "steps_value = round_list_array.shape[0]\n",
    "row_col = round_list_array.shape[1]\n",
    "params = round_list_array.shape[2]\n",
    "rounded_genes_final = round_list_array.reshape(steps_value,int(math.sqrt(row_col)),int(math.sqrt(row_col)),params)\n",
    "\n",
    "rounded_array_further = np.zeros((steps_value,int(math.sqrt(row_col)),int(math.sqrt(row_col)),number_of_random_weights))\n",
    "random_postions = random.sample(range(params), number_of_random_weights)\n",
    "for i in range(steps_value):\n",
    "    for j in range(int(math.sqrt(row_col))):\n",
    "        for k in range(int(math.sqrt(row_col))):\n",
    "            selected_values_array = rounded_genes_final[i][j][k]\n",
    "            selected_values = np.array([selected_values_array[i] for i in random_postions])\n",
    "            rounded_array_further[i][j][k] = selected_values\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = rounded_array_further\n",
    "normalized_data = (data * 255).astype(np.uint8)\n",
    "\n",
    "length = len(normalized_data)\n",
    "\n",
    "if not os.path.exists('gd_rwsp_frames_png'):\n",
    "    os.makedirs('gd_rwsp_frames_png')\n",
    "if not os.path.exists('gd_rwsp_frames_pdf'):\n",
    "    os.makedirs('gd_rwsp_frames_pdf')\n",
    "\n",
    "def save_frame(frame, fig):\n",
    "    im = plt.imshow(normalized_data[frame],cmap='jet')\n",
    "    plt.title(f'Generation {frame + 1}')\n",
    "    cax = fig.add_axes([0.08, 0.94, 0.15, 0.02])\n",
    "    colorbar = fig.colorbar(im, cax=cax, orientation='horizontal', shrink=0.7)\n",
    "    min_value = np.min(normalized_data[frame])\n",
    "    max_value = np.max(normalized_data[frame])\n",
    "    mid_value = (min_value + max_value) / 2\n",
    "    ticks = [min_value, (min_value + mid_value) / 2, mid_value, (mid_value + max_value) / 2, max_value]  # Include midpoints\n",
    "    rounded_ticks = [round(value) for value in ticks]\n",
    "    ticks = rounded_ticks\n",
    "    colorbar.set_ticks(ticks)\n",
    "    colorbar.ax.tick_params(axis='x', labelsize=6)\n",
    "    plt.savefig(os.path.join('gd_rwsp_frames_png', f\"{frame + 1:07d}.png\"), format='png', dpi=600)\n",
    "    plt.savefig(os.path.join('gd_rwsp_frames_pdf', f\"{frame + 1:07d}.pdf\"), format='pdf', dpi=600)\n",
    "    plt.clf()\n",
    "\n",
    "for frame in range(length):\n",
    "    fig = plt.figure()\n",
    "    save_frame(frame,fig)\n",
    "    plt.close(fig)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Display the combined clustering plot\n",
    "frames_folder = 'gd_rwsp_frames_png'\n",
    "frame_files = [f for f in os.listdir(frames_folder) if f.endswith(\".png\")]\n",
    "frame_files.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "frames = []\n",
    "for frame_file in frame_files:\n",
    "    frame_path = os.path.join(frames_folder, frame_file)\n",
    "    frame = Image.open(frame_path)\n",
    "    frames.append(frame)\n",
    "\n",
    "# Define GIF-related parameters\n",
    "output_gif_path = \"tool1_gd_rwsp_gif.gif\"\n",
    "desired_fps = FPS  # Add FPS definition\n",
    "duration = int(1000 / desired_fps)\n",
    "\n",
    "# Save frames as an animated GIF\n",
    "frames[0].save(\n",
    "    output_gif_path,\n",
    "    save_all=True,\n",
    "    append_images=frames[1:],\n",
    "    duration=duration,\n",
    "    loop=0,\n",
    "    disposal=2,\n",
    "    optimize=False\n",
    ")\n",
    "\n",
    "# Save video as well\n",
    "import subprocess\n",
    "\n",
    "# Your Python variable for FPS and bitrate\n",
    "fps = FPS  # replace with your desired value\n",
    "bitrate = 10000  # replace with your desired value\n",
    "\n",
    "# Construct the bash command with both FPS and bitrate variables\n",
    "command = f\"ffmpeg -framerate {fps} -pattern_type glob -i 'gd_rwsp_frames_png/*.png' -c:v libx264 -b:v {bitrate}k -pix_fmt yuv420p tool1_gd_rwsp_video.mp4\"\n",
    "\n",
    "# Run the command quietly (suppress output)\n",
    "subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "source_path = \"tool1_gd_rwsp_video.mp4\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"tool1_gd_rwsp_gif.gif\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"gd_rwsp_frames_png\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"gd_rwsp_frames_pdf\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "# GHC Tool Tool 2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "list_of_weights_at_every_step = round_elements_in_nested_list(this_list_should_contain_NN_for_every_step)\n",
    "sample = list_of_weights_at_every_step\n",
    "sample = np.array(sample)\n",
    "params = sample[0][0].shape[0]\n",
    "sample = sample.reshape(NUM_STEPS+1,WIDTH,HEIGHT,params)\n",
    "height, width = sample.shape[1]-1, sample.shape[2]-1\n",
    "length_sim = sample.shape[0]-1\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "output_folder = \"gd_ghc_frames_png\"\n",
    "output_folder2 = \"gd_ghc_frames_pdf\"\n",
    "\n",
    "# Make sure the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "if not os.path.exists(output_folder2):\n",
    "    os.makedirs(output_folder2)\n",
    "# sample[8][0] # weights of the NN at different time steps\n",
    "# fig, ax = plt.subplots()\n",
    "for i in range(length_sim):\n",
    "  # Function to hash a 44-bit gene sequence to 24 bits using Python's built-in hash function\n",
    "  def hash_gene_sequence(gene_sequence):\n",
    "      return [int(hash(value) % 2) for value in gene_sequence]\n",
    "\n",
    "  # Function to convert a 24-bit sequence to three 8-bit values\n",
    "  def split_to_rgb(sequence):\n",
    "      r = int(''.join(map(str, sequence[:8])), 2)\n",
    "      g = int(''.join(map(str, sequence[8:16])), 2)\n",
    "      b = int(''.join(map(str, sequence[16:24])), 2)\n",
    "      return r, g, b\n",
    "\n",
    "  # Create an empty grid to store the RGB values for each cell\n",
    "  grid = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "  # Populate the grid with color-coded gene sequences\n",
    "  for row in range(height):\n",
    "      for col in range(width):\n",
    "          gene_sequence = sample[i][row][col]\n",
    "          gene_sequence = gene_sequence.tolist()\n",
    "          hashed_sequence = hash_gene_sequence(gene_sequence)\n",
    "          r, g, b = split_to_rgb(hashed_sequence)\n",
    "          grid[row, col] = [r, g, b]\n",
    "  frame_filename = os.path.join(output_folder2, f\"{i + 1:07d}.pdf\")\n",
    "  fig = plt.figure()\n",
    "  im = plt.imshow(grid,interpolation='none',cmap='jet')\n",
    "  plt.title(f'Generation {i + 1}')\n",
    "  cax = fig.add_axes([0.08, 0.94, 0.15, 0.02])\n",
    "  colorbar = fig.colorbar(im, cax=cax, orientation='horizontal', shrink=0.7)\n",
    "  min_value = np.min(grid)\n",
    "  max_value = np.max(grid)\n",
    "  mid_value = (min_value + max_value) / 2\n",
    "  ticks = [min_value, (min_value + mid_value) / 2, mid_value, (mid_value + max_value) / 2, max_value]  # Include midpoints\n",
    "  rounded_ticks = [round(value) for value in ticks]\n",
    "  ticks = rounded_ticks\n",
    "  colorbar.set_ticks(ticks)\n",
    "  colorbar.ax.tick_params(axis='x', labelsize=6)\n",
    "  # plt.axis('off')\n",
    "  plt.savefig(frame_filename,format='pdf',dpi=600)\n",
    "  frame_filename = os.path.join(output_folder, f\"{i + 1:07d}.png\")\n",
    "  plt.savefig(frame_filename,format='png',dpi=600)\n",
    "  plt.close()\n",
    "\n",
    "# Display the combined clustering plot\n",
    "frames_folder = output_folder\n",
    "frame_files = [f for f in os.listdir(frames_folder) if f.endswith(\".png\")]\n",
    "frame_files.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "frames = []\n",
    "for frame_file in frame_files:\n",
    "    frame_path = os.path.join(frames_folder, frame_file)\n",
    "    frame = Image.open(frame_path)\n",
    "    frames.append(frame)\n",
    "\n",
    "# Define GIF-related parameters\n",
    "output_gif_path = \"tool2_gd_ghc_gif.gif\"\n",
    "desired_fps = FPS  # Add FPS definition\n",
    "duration = int(1000 / desired_fps)\n",
    "\n",
    "# Save frames as an animated GIF\n",
    "frames[0].save(\n",
    "    output_gif_path,\n",
    "    save_all=True,\n",
    "    append_images=frames[1:],\n",
    "    duration=duration,\n",
    "    loop=0,\n",
    "    disposal=2,\n",
    "    optimize=False\n",
    ")\n",
    "\n",
    "\n",
    "# Save video as well\n",
    "import subprocess\n",
    "\n",
    "# Your Python variable for FPS and bitrate\n",
    "fps = FPS  # replace with your desired value\n",
    "bitrate = 10000  # replace with your desired value\n",
    "\n",
    "# Construct the bash command with both FPS and bitrate variables\n",
    "command = f\"ffmpeg -framerate {fps} -pattern_type glob -i 'gd_ghc_frames_png/*.png' -c:v libx264 -b:v {bitrate}k -pix_fmt yuv420p tool2_gd_ghc_video.mp4\"\n",
    "\n",
    "# Run the command quietly (suppress output)\n",
    "subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "source_path = \"tool2_gd_ghc_video.mp4\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"tool2_gd_ghc_gif.gif\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"gd_ghc_frames_png\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"gd_ghc_frames_pdf\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "\n",
    "# CNWA Tool 3\n",
    "\n",
    "output_folder = \"gd_cnwa_frames_png\"\n",
    "output_folder2 = \"gd_cnwa_frames_pdf\"\n",
    "\n",
    "# Make sure the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "if not os.path.exists(output_folder2):\n",
    "    os.makedirs(output_folder2)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "k = KMEANS_K  # Set smaller value for smaller runs\n",
    "this_list_should_contain_NN_for_every_step = everystep_weights\n",
    "list_of_weights_at_every_step = round_elements_in_nested_list(this_list_should_contain_NN_for_every_step)\n",
    "marker_size = marker_size  # Add marker size definition\n",
    "\n",
    "# Initialize colors for clusters based on initial assignment\n",
    "initial_colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'brown']\n",
    "\n",
    "# Initialize centroids only once based on the first frame\n",
    "initial_frame_weights = list_of_weights_at_every_step[0]\n",
    "initial_centroids = KMeans(n_clusters=k, random_state=0, n_init=1).fit(\n",
    "    StandardScaler().fit_transform(initial_frame_weights)).cluster_centers_\n",
    "\n",
    "# Dictionary to store cluster colors based on initial assignment\n",
    "cluster_colors = {cluster_id: initial_colors[cluster_id] for cluster_id in range(k)}\n",
    "\n",
    "# Store centroid data for each step\n",
    "centroid_data = []\n",
    "cluster_data = []  # Modified: Initialize cluster_data list to store cluster counts for each step\n",
    "for i in range(len(list_of_weights_at_every_step)):\n",
    "    weight_parameters = list_of_weights_at_every_step[i]\n",
    "    normalized_data = StandardScaler().fit_transform(weight_parameters)\n",
    "\n",
    "    # Use the initial centroids for k-means clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=1, init=initial_centroids)\n",
    "    kmeans.fit(normalized_data)\n",
    "    clusters = kmeans.predict(normalized_data)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_data = pca.fit_transform(normalized_data)\n",
    "\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    plt.suptitle(f'Generation {i + 1}')\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    # Plot the cluster points on the left subplot\n",
    "    for cluster_id in range(k):\n",
    "        cluster_points = reduced_data[clusters == cluster_id]\n",
    "        axs[0].scatter(cluster_points[:, 0], cluster_points[:, 1], s=marker_size, label=f'Cluster {cluster_id}',\n",
    "                       c=cluster_colors[cluster_id])\n",
    "\n",
    "    # Highlight the centroids with larger markers\n",
    "    axs[0].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=2 * marker_size, marker='X',\n",
    "                   c='black', label='Centroids')\n",
    "    axs[0].set_title(f'K-Means Clustering (k={k})')\n",
    "\n",
    "    # Plot the count of points for each cluster on the right subplot\n",
    "    cluster_counts = np.bincount(clusters, minlength=k)  # Ensure that the cluster counts have length k\n",
    "    cluster_data.append(cluster_counts)\n",
    "\n",
    "    bar_container = axs[1].bar(list(range(k)), cluster_counts, color=[cluster_colors[cluster_id] for cluster_id in range(k)])\n",
    "    axs[1].set_title('Cluster Point Counts')\n",
    "\n",
    "    # Add labels on top of each bar\n",
    "    for rect, value in zip(bar_container, cluster_counts):\n",
    "        height = rect.get_height()\n",
    "        axs[1].text(rect.get_x() + rect.get_width() / 2, height, f'{value}', ha='center', va='bottom')\n",
    "\n",
    "    # Save the combined plot\n",
    "    # frames_folder = \"TOOL2_GD_FRAMES_CLUSTERING\"\n",
    "    # if not os.path.exists(frames_folder):\n",
    "    #     os.makedirs(frames_folder)\n",
    "    filename = os.path.join(output_folder, '{:07d}.png'.format(i))\n",
    "    plt.savefig(filename, format='png', dpi=600)\n",
    "    filename = os.path.join(output_folder2, '{:07d}.pdf'.format(i))\n",
    "    plt.savefig(filename, format='pdf', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "    # Save centroid data for each step\n",
    "    centroid_data.append(kmeans.cluster_centers_)\n",
    "\n",
    "# Display the combined clustering plot\n",
    "frames_folder = output_folder\n",
    "frame_files = [f for f in os.listdir(frames_folder) if f.endswith(\".png\")]\n",
    "frame_files.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "frames = []\n",
    "for frame_file in frame_files:\n",
    "    frame_path = os.path.join(frames_folder, frame_file)\n",
    "    frame = Image.open(frame_path)\n",
    "    frames.append(frame)\n",
    "\n",
    "# Define GIF-related parameters\n",
    "output_gif_path = \"tool3_gd_cnwa_gif.gif\"\n",
    "desired_fps = FPS  # Add FPS definition\n",
    "duration = int(1000 / desired_fps)\n",
    "\n",
    "# Save frames as an animated GIF\n",
    "frames[0].save(\n",
    "    output_gif_path,\n",
    "    save_all=True,\n",
    "    append_images=frames[1:],\n",
    "    duration=duration,\n",
    "    loop=0,\n",
    "    disposal=2,\n",
    "    optimize=False\n",
    ")\n",
    "\n",
    "\n",
    "# Save video as well\n",
    "import subprocess\n",
    "\n",
    "# Your Python variable for FPS and bitrate\n",
    "fps = FPS  # replace with your desired value\n",
    "bitrate = 10000  # replace with your desired value\n",
    "\n",
    "# Construct the bash command with both FPS and bitrate variables\n",
    "command = f\"ffmpeg -framerate {fps} -pattern_type glob -i 'gd_cnwa_frames_png/*.png' -c:v libx264 -b:v {bitrate}k -pix_fmt yuv420p tool3_gd_cnwa_video.mp4\"\n",
    "\n",
    "# Run the command quietly (suppress output)\n",
    "subprocess.run(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "source_path = \"tool3_gd_cnwa_video.mp4\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"tool3_gd_cnwa_gif.gif\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"gd_cnwa_frames_png\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"gd_cnwa_frames_pdf\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "\n",
    "# Tool 3.1 GD Plot Kernel Density\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = cluster_data\n",
    "data = np.array(data)\n",
    "# Number of species and number of steps\n",
    "n = data.shape[0] # Number of steps\n",
    "k = data.shape[1] # Number of species\n",
    "\n",
    "\n",
    "# Generate random data for k species and n steps\n",
    "data = data.flatten()\n",
    "species_labels = [f'Species {i}' for i in range(1, k + 1) for _ in range(n)]\n",
    "\n",
    "# Create a DataFrame for Seaborn\n",
    "data_df = pd.DataFrame({'Value': data, 'Species': species_labels})\n",
    "\n",
    "# Create a KDE plot using Seaborn\n",
    "sns.kdeplot(data=data_df, x='Value', hue='Species', fill=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.title(f'KDE Plot for {k} Species over {n} Steps')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.savefig(\"tool3_plot1_GD.pdf\",format='pdf', dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Tool 3.2 GD Plot Speciation Bar Plot\n",
    "\n",
    "# Import necessary libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming cluster_data is a 2D array with dimensions (number_of_steps, number_of_species)\n",
    "data = np.array(cluster_data)\n",
    "\n",
    "# Calculate proportions for each step\n",
    "proportions = data / data.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Create a DataFrame for Seaborn\n",
    "proportions_df = pd.DataFrame(proportions, columns=[f'Species {i}' for i in range(1, data.shape[1] + 1)])\n",
    "\n",
    "# Define colors for each species\n",
    "species_colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "\n",
    "proportions_df.plot(kind='bar', stacked=True, width=1.0, color=species_colors, ax=ax)\n",
    "\n",
    "# Modify x-axis and y-axis labels\n",
    "ax.set(xlabel='Step', ylabel='Proportion')\n",
    "\n",
    "\n",
    "def calculate_proportions(input_value, num_parts):\n",
    "    # Calculate the size of each proportion\n",
    "    proportion_size = input_value // num_parts\n",
    "\n",
    "    # Generate the list of proportions\n",
    "    proportions = [proportion_size * i for i in range(1, num_parts + 1)]\n",
    "\n",
    "    return proportions\n",
    "\n",
    "# # Example usage\n",
    "# input_value = 1000\n",
    "# num_parts = 3\n",
    "# result = calculate_proportions(input_value, num_parts)\n",
    "# print(result)\n",
    "\n",
    "\n",
    "\n",
    "# Set x-axis ticks and labels to every 5th value\n",
    "xticks_positions = calculate_proportions(NUM_STEPS,15)\n",
    "xticks_labels = [str(i) for i in xticks_positions]\n",
    "\n",
    "ax.set_xticks(xticks_positions)\n",
    "ax.set_xticklabels(xticks_labels)\n",
    "\n",
    "# Move the legend outside the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.title(f'Stacked Bar Plot for Proportions of Species over Steps')\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.savefig(\"tool3_plot2_GD.pdf\", format='pdf', bbox_inches='tight', dpi=600)  # Use bbox_inches to include the legend properly\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Tool 3.3 GD Plot Speciation Bar Plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming cluster_data is a 2D array with dimensions (number_of_steps, number_of_species)\n",
    "data = np.array(cluster_data)\n",
    "\n",
    "# Calculate proportions for each step\n",
    "proportions = data / data.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Create a DataFrame for Seaborn\n",
    "proportions_df = pd.DataFrame(proportions, columns=[f'Species {i}' for i in range(1, data.shape[1] + 1)])\n",
    "\n",
    "# Define colors for each species\n",
    "species_colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "# Create an area plot using fill_between\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Calculate cumulative sum for each species\n",
    "cumulative_proportions = np.cumsum(proportions, axis=1)\n",
    "\n",
    "for i, col in enumerate(proportions_df.columns):\n",
    "    # For the first species, fill between 0 and the proportion\n",
    "    if i == 0:\n",
    "        ax.fill_between(proportions_df.index, 0, cumulative_proportions[:, i], label=col, color=species_colors[i])\n",
    "    # For subsequent species, fill between the cumulative sum of the previous species and the current species\n",
    "    else:\n",
    "        ax.fill_between(proportions_df.index, cumulative_proportions[:, i - 1], cumulative_proportions[:, i], label=col, color=species_colors[i])\n",
    "\n",
    "# Modify x-axis and y-axis labels\n",
    "ax.set(xlabel='Step', ylabel='Proportion')\n",
    "\n",
    "# Move the legend outside the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.title(f'Area Plot for Proportions of Species over Steps')\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.savefig(\"tool3_plot3_GD.pdf\", format='pdf', bbox_inches='tight',dpi=600)  # Use bbox_inches to include the legend properly\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "source_path = \"tool3_plot3_GD.pdf\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "source_path = \"tool3_plot2_GD.pdf\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "\n",
    "source_path = \"tool3_plot1_GD.pdf\"\n",
    "destination_path = 'GD'\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "# Outputs\n",
    "\n",
    "source_path = \"GD\"\n",
    "destination_path = 'Outputs_'+str(output_stamp)\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"NCA\"\n",
    "destination_path = 'Outputs_'+str(output_stamp)\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"PD\"\n",
    "destination_path = 'Outputs_'+str(output_stamp)\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "source_path = \"interestingoutput.out\"\n",
    "destination_path = 'Outputs_'+str(output_stamp)\n",
    "shutil.move(source_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc3935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
